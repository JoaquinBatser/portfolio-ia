---
title: "Escalado inteligente y pipelines anti-leakage: Optimizando modelos con preprocessing robusto"
description: "Exploraci√≥n avanzada de t√©cnicas de feature scaling y prevenci√≥n de data leakage en pipelines de machine learning usando el dataset Ames Housing."
---


## Objetivos de Aprendizaje

- **Identificar features problem√°ticas** que requieren escalado en datasets reales
- **Experimentar con diferentes scalers** (MinMaxScaler, StandardScaler, RobustScaler)
- **Descubrir el impacto del escalado** en algoritmos basados en distancia vs. tree-based
- **Comparar pipelines** con y sin data leakage para evidenciar diferencias
- **Desarrollar estrategias robustas** de preprocessing basadas en evidencia emp√≠rica

## Contexto de Negocio

El dataset **Ames Housing** presenta un desaf√≠o real de escalado: variables con rangos extremadamente diferentes que pueden sesgar algoritmos de machine learning. Como data scientists, debemos:

- **Identificar autom√°ticamente** features con escalas problem√°ticas
- **Seleccionar el scaler apropiado** seg√∫n caracter√≠sticas de los datos
- **Prevenir data leakage** en pipelines de producci√≥n
- **Evaluar el impacto** del escalado en diferentes tipos de algoritmos

### Relevancia del Problema

En modelos de predicci√≥n inmobiliaria, el escalado inadecuado puede:
- **Sesgar algoritmos basados en distancia** (KNN, SVM) hacia features con mayor escala
- **Afectar la convergencia** de algoritmos de optimizaci√≥n
- **Introducir data leakage** si se escala incorrectamente
- **Reducir la interpretabilidad** del modelo

## Proceso de An√°lisis

### 1. Configuraci√≥n del Entorno

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor  
from sklearn.svm import SVR
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Configurar visualizaciones
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (14, 8)
plt.rcParams['font.size'] = 11
```

### 2. Exploraci√≥n de Escalas Problem√°ticas

```python
# Cargar dataset Ames Housing
df_raw = pd.read_csv('AmesHousing.csv')

# Identificar columnas num√©ricas
numeric_cols = df_raw.select_dtypes(include=[np.number]).columns.tolist()

# Seleccionar features con escalas problem√°ticas
selected_features = [
    'SalePrice', 'Lot Area', 'Overall Qual', 'Year Built', '1st Flr SF', 'Gr Liv Area'
]

# Analizar escalas
scale_analysis = {}
for col in selected_features:
    col_min = df_raw[col].min()
    col_max = df_raw[col].max()
    ratio = col_max / col_min if col_min != 0 else np.inf
    scale_analysis[col] = {
        'min': col_min,
        'max': col_max,
        'ratio': ratio
    }

scale_df = pd.DataFrame(scale_analysis).T
print("üìà An√°lisis de escalas:")
print(scale_df.sort_values(by='ratio', ascending=False))
```

### 3. Visualizaci√≥n del Problema de Escalas

```python
# Visualizar distribuciones
plt.figure(figsize=(16, 12))
for i, col in enumerate(selected_features):
    plt.subplot(3, len(selected_features)//3 + 1, i+1) 
    sns.boxplot(x=df_raw[col])
    plt.title(f'Boxplot de {col}')
    plt.xlabel(col)
    plt.grid(True)
plt.tight_layout()

# Histogramas con KDE
plt.figure(figsize=(16, 12))
for i, col in enumerate(selected_features):
    plt.subplot(3, len(selected_features)//3 + 1, i+1) 
    sns.histplot(df_raw[col], bins=30, kde=True)
    plt.title(f'Distribuci√≥n de {col}')
    plt.xlabel(col)
    plt.ylabel('Frecuencia')
    plt.grid(True)
plt.tight_layout()
```

![Histogramas de Distribuciones](/images/practica6/histogramas.png)

**Pie de figura:** Este gr√°fico muestra las distribuciones de las features num√©ricas del dataset Ames Housing antes del escalado. Lo que me llam√≥ la atenci√≥n es la enorme diferencia en escalas: `Lot Area` tiene valores que van desde 1,300 hasta 215,245, mientras que `Overall Qual` solo va de 1 a 10, lo que representa un ratio de m√°s de 165:1. La conclusi√≥n es que estas diferencias de escala distorsionar√≠an significativamente algoritmos basados en distancia (como KNN o SVM), donde features con mayor escala dominar√≠an el c√°lculo de distancias, haciendo que features con menor escala pero potencialmente m√°s informativas tengan menos peso en el modelo.

### 4. Preparaci√≥n de Datos y Split Anti-Leakage

```python
# Definir target y features
target_col = 'SalePrice'
feature_cols = ['Lot Area', 'Overall Qual', 'Year Built', '1st Flr SF', 'Gr Liv Area']

# Limpiar datos
df_clean = df_raw[feature_cols + [target_col]].dropna()

# Split ANTES de cualquier transformaci√≥n (cr√≠tico para evitar leakage)
X = df_clean[feature_cols]
y = df_clean[target_col]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

X_train, X_val, y_train, y_val = train_test_split(
    X_train, y_train, test_size=0.25, random_state=42
)

print(f"Train: {X_train.shape}, Validation: {X_val.shape}, Test: {X_test.shape}")
```

### 5. Experimentaci√≥n con Diferentes Scalers

```python
# Configurar scalers
scalers = {
    'MinMax': MinMaxScaler(),
    'Standard': StandardScaler(),
    'Robust': RobustScaler(),
    'None': None
}

# Algoritmos a probar
# Decisiones de hiperpar√°metros:
# - Random Forest: n_estimators=100 es un buen balance entre rendimiento y tiempo de entrenamiento
# - K-NN: n_neighbors=5 es un valor est√°ndar que funciona bien para la mayor√≠a de datasets
# - SVM: C=100 y kernel='rbf' permiten flexibilidad en el ajuste; kernel RBF es vers√°til para datos no lineales
algorithms = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
    'K-NN': KNeighborsRegressor(n_neighbors=5),
    'SVM': SVR(kernel='rbf', C=100)
}

# Experimentar combinaciones
results = {}
for scaler_name, scaler in scalers.items():
    for algo_name, algorithm in algorithms.items():
        if scaler is None:
            # Sin escalado
            pipeline = Pipeline([('model', algorithm)])
        else:
            # Con escalado
            pipeline = Pipeline([
                ('scaler', scaler),
                ('model', algorithm)
            ])
        
        # Entrenar y evaluar
        pipeline.fit(X_train, y_train)
        y_pred = pipeline.predict(X_val)
        
        r2 = r2_score(y_val, y_pred)
        mae = mean_absolute_error(y_val, y_pred)
        
        results[f"{scaler_name}_{algo_name}"] = {
            'R2': r2,
            'MAE': mae
        }

# Convertir a DataFrame para an√°lisis
results_df = pd.DataFrame(results).T
results_df[['Scaler', 'Algorithm']] = results_df.index.str.split('_', expand=True)
print("üìä Resultados de experimentaci√≥n:")
print(results_df.pivot(index='Algorithm', columns='Scaler', values='R2'))
```

### 6. An√°lisis de Data Leakage

```python
# Escenario CON leakage (INCORRECTO)
def pipeline_with_leakage(X_train, X_val, y_train, y_val):
    # ERRO: Escalar todo el dataset junto
    scaler = StandardScaler()
    X_all_scaled = scaler.fit_transform(pd.concat([X_train, X_val]))
    
    X_train_scaled = X_all_scaled[:len(X_train)]
    X_val_scaled = X_all_scaled[len(X_train):]
    
    model = LinearRegression()
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_val_scaled)
    
    return r2_score(y_val, y_pred)

# Escenario SIN leakage (CORRECTO)
def pipeline_without_leakage(X_train, X_val, y_train, y_val):
    # CORRECTO: Fit solo en train, transform en ambos
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    
    model = LinearRegression()
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_val_scaled)
    
    return r2_score(y_val, y_pred)

# Comparar resultados
r2_with_leakage = pipeline_with_leakage(X_train, X_val, y_train, y_val)
r2_without_leakage = pipeline_without_leakage(X_train, X_val, y_train, y_val)

print(f"R¬≤ CON leakage: {r2_with_leakage:.4f}")
print(f"R¬≤ SIN leakage: {r2_without_leakage:.4f}")
print(f"Diferencia: {r2_with_leakage - r2_without_leakage:.4f}")
```

### 7. Pipeline de Producci√≥n Robusto

```python
from sklearn.compose import ColumnTransformer

def create_production_pipeline(numeric_features, categorical_features=None):
    """Crear pipeline robusto para producci√≥n"""
    
    # Transformador num√©rico
    # Eleg√≠ RobustScaler sobre StandardScaler porque los datos inmobiliarios tienen outliers leg√≠timos
    # (propiedades de lujo, lotes muy grandes). RobustScaler usa mediana e IQR en lugar de media y desviaci√≥n
    # est√°ndar, lo que lo hace resistente a valores extremos que podr√≠an distorsionar el escalado.
    numeric_transformer = Pipeline(steps=[
        ('scaler', RobustScaler())  # Robusto a outliers
    ])
    
    # Transformador categ√≥rico (si aplicable)
    if categorical_features:
        from sklearn.preprocessing import OneHotEncoder
        categorical_transformer = Pipeline(steps=[
            ('onehot', OneHotEncoder(handle_unknown='ignore'))
        ])
        
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', numeric_transformer, numeric_features),
                ('cat', categorical_transformer, categorical_features)
            ]
        )
    else:
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', numeric_transformer, numeric_features)
            ]
        )
    
    # Pipeline completo
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))
    ])
    
    return pipeline

# Crear y entrenar pipeline de producci√≥n
production_pipeline = create_production_pipeline(feature_cols)
production_pipeline.fit(X_train, y_train)

# Evaluar en conjunto de prueba
y_test_pred = production_pipeline.predict(X_test)
test_r2 = r2_score(y_test, y_test_pred)
test_mae = mean_absolute_error(y_test, y_test_pred)

print(f"üìà Resultados en test set:")
print(f"R¬≤: {test_r2:.4f}")
print(f"MAE: ${test_mae:,.2f}")
```

### 8. Investigaci√≥n de Transformadores Avanzados

Para completar el an√°lisis, se explor√≥ el comportamiento de transformadores m√°s avanzados:

![Yeo-Johnson PowerTransformer](/images/practica6/YeoJohnson.png)

**Pie de figura:** Este gr√°fico muestra el efecto del transformador Yeo-Johnson en la distribuci√≥n de las features. Lo que me llam√≥ la atenci√≥n es c√≥mo Yeo-Johnson normaliza las distribuciones sin requerir valores estrictamente positivos (a diferencia de Box-Cox), lo cual es √∫til para datos que pueden tener ceros o valores negativos. La conclusi√≥n es que Yeo-Johnson es especialmente valioso para features como `SalePrice` donde queremos normalizar la distribuci√≥n pero no podemos usar transformaciones logar√≠tmicas directas debido a la presencia de valores en cero o cercanos a cero.

![QuantileTransformer](/images/practica6/QuantileTransformer.png)

**Pie de figura:** Este gr√°fico muestra el efecto del QuantileTransformer, que mapea las distribuciones a una distribuci√≥n uniforme y luego a una normal. Lo que me llam√≥ la atenci√≥n es c√≥mo este transformador puede manejar distribuciones extremadamente sesgadas y convertirlas en distribuciones normales, independientemente de la forma original. La conclusi√≥n es que QuantileTransformer es muy robusto pero puede ser computacionalmente costoso y puede crear artefactos si hay muchos valores duplicados, por lo que es mejor usarlo cuando otros m√©todos fallan o cuando necesitamos distribuciones estrictamente normales para ciertos algoritmos.

![MaxAbsScaler](/images/practica6/MaxAbsScaler.png)

**Pie de figura:** Este gr√°fico muestra el efecto del MaxAbsScaler, que escala cada feature dividiendo por su valor absoluto m√°ximo, resultando en valores en el rango [-1, 1]. Lo que me llam√≥ la atenci√≥n es que este scaler preserva la informaci√≥n de signo (importante para features que pueden tener valores negativos) y es robusto ante outliers ya que solo usa el m√°ximo absoluto, no la desviaci√≥n est√°ndar. La conclusi√≥n es que MaxAbsScaler es √∫til cuando tenemos features dispersas (con muchos ceros) y queremos un escalado que no se vea afectado por outliers, aunque no centra los datos en cero como StandardScaler.

![Normalizer L2](/images/practica6/NormalizerL2.png)

**Pie de figura:** Este gr√°fico muestra el efecto del Normalizer L2, que normaliza cada fila (muestra) en lugar de cada columna (feature), escalando cada muestra para que tenga norma L2 igual a 1. Lo que me llam√≥ la atenci√≥n es que este enfoque es fundamentalmente diferente: normaliza muestras en lugar de features, lo cual es √∫til para algoritmos que miden distancias entre muestras completas. La conclusi√≥n es que Normalizer es apropiado para casos espec√≠ficos como an√°lisis de texto o im√°genes donde queremos comparar documentos/im√°genes completas, pero generalmente no es el enfoque correcto para la mayor√≠a de problemas de regresi√≥n donde queremos escalar features individuales.

![FunctionTransformer (Log)](/images/practica6/FunctionTransformer.png)

**Pie de figura:** Este gr√°fico muestra el efecto de una transformaci√≥n logar√≠tmica usando FunctionTransformer. Lo que me llam√≥ la atenci√≥n es c√≥mo la transformaci√≥n log comprime los valores grandes y expande los valores peque√±os, reduciendo la asimetr√≠a (skewness) de distribuciones sesgadas a la derecha. La conclusi√≥n es que las transformaciones logar√≠tmicas son especialmente √∫tiles para features como `SalePrice` o `Lot Area` que tienen distribuciones exponenciales, pero requieren que todos los valores sean estrictamente positivos, lo cual puede ser una limitaci√≥n en algunos datasets.

![Comparaci√≥n de Transformaci√≥n Logar√≠tmica](/images/practica6/comparacionlogs.png)

**Pie de figura:** Este gr√°fico compara las distribuciones antes y despu√©s de aplicar transformaciones logar√≠tmicas. Lo que me llam√≥ la atenci√≥n es la mejora significativa en la normalidad de las distribuciones despu√©s de la transformaci√≥n log, especialmente para `SalePrice` que pasa de una distribuci√≥n fuertemente sesgada a la derecha a una distribuci√≥n m√°s sim√©trica. La conclusi√≥n es que las transformaciones logar√≠tmicas pueden ser muy efectivas como preprocesamiento antes del escalado, especialmente cuando seguimos con StandardScaler, ya que este √∫ltimo asume distribuciones aproximadamente normales para funcionar √≥ptimamente.

## Hallazgos Clave

### An√°lisis de Escalas

| Variable     | Rango (min‚Äìmax) | Ratio | ¬øProblem√°tica? | Raz√≥n |
|-------------|-----------------|-------|----------------|-------|
| Lot Area    | 1,300‚Äì215,245   | 165.6 | **S√≠**         | Rango extremo, outliers dominan |
| SalePrice   | 12,789‚Äì755,000  | 59.0  | **S√≠**         | Alta variabilidad afecta distancias |
| Overall Qual| 1‚Äì10            | 10.0  | No             | Escala controlada |

### Impacto por Algoritmo

1. **Algoritmos basados en distancia** (KNN, SVM): Mejora significativa con escalado
2. **Tree-based models** (Random Forest): Poco impacto del escalado
3. **Modelos lineales**: Beneficio moderado, especialmente con outliers

### Mejores Pr√°cticas Identificadas

1. **RobustScaler**: Mejor opci√≥n para datos con outliers
2. **StandardScaler**: Ideal para distribuciones normales
3. **MinMaxScaler**: √ötil cuando se necesita rango espec√≠fico [0,1]

## Consideraciones √âticas y de Calidad

### Prevenci√≥n de Data Leakage

- **Fit solo en training set**: Nunca ajustar transformaciones en validation/test
- **Pipeline autom√°tico**: Usar sklearn Pipeline para garantizar orden correcto
- **Validaci√≥n cruzada**: Aplicar escalado dentro de cada fold

### Transparencia del Modelo

- **Documentar decisiones**: Registrar por qu√© se eligi√≥ cada scaler
- **Monitorear drift**: Verificar si las escalas cambian en producci√≥n
- **Interpretabilidad**: Considerar impacto del escalado en explicabilidad

### Robustez en Producci√≥n

- **Manejo de outliers**: RobustScaler m√°s resistente a valores extremos
- **Datos faltantes**: Pipeline debe manejar NaN gracefully
- **Escalado inverso**: Capacidad de des-escalar predicciones si necesario

## Recursos Adicionales

### Enlaces √ötiles
- [Scikit-learn Preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html)
- [Feature Engineering for Machine Learning](https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/)
- [Kaggle Feature Scaling Guide](https://www.kaggle.com/learn/feature-engineering)

### Herramientas Utilizadas
- **scikit-learn**: Scalers y pipelines
- **pandas/numpy**: Manipulaci√≥n de datos
- **matplotlib/seaborn**: Visualizaciones
- **Pipeline**: Automatizaci√≥n anti-leakage

## Conclusi√≥n

El escalado de features es crucial para el rendimiento de muchos algoritmos de machine learning, pero debe implementarse cuidadosamente para evitar data leakage. La experimentaci√≥n sistem√°tica revel√≥ que RobustScaler ofrece la mejor combinaci√≥n de robustez y rendimiento para el dataset Ames Housing, especialmente en presencia de outliers. Los pipelines automatizados garantizan reproducibilidad y previenen errores comunes en producci√≥n. Los hallazgos clave incluyen: algoritmos basados en distancia (KNN, SVM) mejoran significativamente con escalado, mientras que tree-based models (Random Forest) son relativamente insensibles al escalado; RobustScaler es superior a StandardScaler cuando hay outliers, y la prevenci√≥n de data leakage mediante split antes de escalar es cr√≠tica para obtener m√©tricas de validaci√≥n confiables.

**Pr√≥ximos pasos:** Realizar una b√∫squeda sistem√°tica de hiperpar√°metros (GridSearchCV) para optimizar los valores de `n_neighbors` en KNN, `C` y `gamma` en SVM, y `n_estimators` en Random Forest, evaluando el impacto del escalado en cada combinaci√≥n. Implementar validaci√≥n cruzada estratificada para asegurar que las m√©tricas reportadas sean representativas del rendimiento real. Explorar t√©cnicas de escalado adaptativo que aprendan a ajustarse autom√°ticamente a las caracter√≠sticas de cada feature (por ejemplo, usando transformaciones log antes de StandardScaler para features sesgadas). Desarrollar un framework de monitoreo que detecte drift en las escalas de features en producci√≥n y alerte cuando sea necesario re-entrenar los scalers. Comparar el impacto de diferentes estrategias de escalado en modelos de ensemble que combinen m√∫ltiples algoritmos.

---