---
title: "Exploración del dataset Iris"
description: "Introducción al Análisis Exploratorio de Datos (EDA) utilizando el clásico dataset Iris. Carga de datos, estadísticas descriptivas, visualización y detección de patrones."
---

## Objetivos de Aprendizaje

- **Dominar la carga de datos** desde múltiples fuentes (Seaborn, Scikit-learn, CSV).
- **Realizar chequeos básicos** de calidad de datos (tipos, nulos, duplicados).
- **Implementar visualizaciones** fundamentales para el análisis exploratorio (histogramas, scatterplots, pairplots).
- **Identificar patrones y correlaciones** entre variables.
- **Documentar hallazgos** de manera estructurada.

## Contexto de Negocio

El dataset Iris es un conjunto de datos multivariado introducido por Ronald Fisher en 1936. Se utiliza comúnmente para enseñar técnicas de clasificación y análisis de datos. El objetivo es clasificar las flores de Iris en tres especies (setosa, versicolor y virginica) basándose en cuatro características: largo y ancho del sépalo, y largo y ancho del pétalo.

### Preguntas de Negocio

1.  ¿Se pueden separar las especies utilizando solo 1 o 2 variables?
2.  ¿Qué variables están más fuertemente correlacionadas?
3.  ¿Existen valores atípicos (outliers) en las mediciones?
4.  ¿Están balanceadas las clases (especies) en el dataset?

## Proceso de Análisis

### 1. Configuración y Carga de Datos

Utilizamos Python con las librerías `pandas`, `seaborn` y `matplotlib`.

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Configuración visual
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# Cargar dataset desde seaborn
df = sns.load_dataset('iris')
print(f"Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas")
df.head()
```

### 2. Chequeos Básicos y Diccionario de Datos

Verificamos tipos de datos, valores nulos y estadísticas descriptivas.

```python
# Información general
df.info()

# Estadísticas descriptivas
display(df.describe())

# Chequeo de nulos
print("\nValores nulos por columna:")
print(df.isnull().sum())
```

**Diccionario de Datos:**

| Nombre | Tipo | Unidad | Descripción |
| :--- | :--- | :--- | :--- |
| `sepal_length` | float | cm | Largo del sépalo |
| `sepal_width` | float | cm | Ancho del sépalo |
| `petal_length` | float | cm | Largo del pétalo |
| `petal_width` | float | cm | Ancho del pétalo |
| `species` | object | - | Especie de la flor (setosa, versicolor, virginica) |

### 3. Análisis Estadístico

Analizamos las correlaciones entre las variables numéricas.

```python
# Matriz de correlación
corr = df.select_dtypes('number').corr()
display(corr)
```

### 4. Visualizaciones

#### Pairplot
El pairplot nos permite ver las relaciones entre todas las variables a la vez, separadas por especie.

```python
sns.pairplot(df, hue='species', height=2.5)
plt.show()
```

![Pairplot Iris](/images/iris/pairplot.png)

**Pie de figura:** Este gráfico muestra las relaciones bivariadas entre todas las características del dataset, coloreadas por especie. Lo que me llamó la atención es que la especie *Setosa* es linealmente separable de las otras dos en casi todas las combinaciones de variables, especialmente usando las dimensiones del pétalo. La conclusión es que `petal_length` y `petal_width` son las variables más discriminantes para clasificar las especies.

#### Mapa de Calor de Correlaciones

```python
plt.figure(figsize=(8, 6))
sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Matriz de Correlación')
plt.show()
```

![Heatmap Iris](/images/iris/heatmap.png)

**Pie de figura:** Este heatmap visualiza la intensidad de las correlaciones entre variables numéricas. Lo que me llamó la atención es la altísima correlación positiva (0.96) entre el largo y ancho del pétalo. La conclusión es que estas dos variables aportan información redundante, lo que sugiere que podríamos usar solo una de ellas en modelos simples o aplicar técnicas de reducción de dimensionalidad como PCA.

#### Boxplots por Especie

```python
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
sns.boxplot(x='species', y='petal_length', data=df)
plt.title('Distribución de Largo de Pétalo por Especie')

plt.subplot(1, 2, 2)
sns.boxplot(x='species', y='sepal_width', data=df)
plt.title('Distribución de Ancho de Sépalo por Especie')
plt.show()
```

![Boxplots Iris](/images/iris/boxplots.png)

**Pie de figura:** Estos boxplots comparan las distribuciones de largo de pétalo y ancho de sépalo entre especies. Lo que me llamó la atención es que *Setosa* tiene pétalos significativamente más pequeños y con muy poca varianza en comparación con *Virginica*. Además, se observan algunos outliers en *Virginica* para el ancho de sépalo. La conclusión es que el largo del pétalo es un excelente predictor por sí solo, mientras que el ancho del sépalo tiene mucho solapamiento entre especies y es menos útil para clasificación.

## Insights Clave

1.  **Separabilidad de Setosa**: La especie *Setosa* es fácilmente distinguible de *Versicolor* y *Virginica* debido a sus pétalos significativamente más pequeños.
2.  **Correlación Pétalo-Pétalo**: Existe una correlación casi perfecta (0.96) entre el largo y el ancho del pétalo, indicando redundancia de información.
3.  **Solapamiento Versicolor-Virginica**: Estas dos especies son más difíciles de separar, aunque el largo del pétalo sigue siendo una buena variable discriminante.
4.  **Calidad de Datos**: El dataset está limpio, sin valores nulos y con clases perfectamente balanceadas (50 muestras por especie), lo que lo hace ideal para pruebas de concepto.

## Conclusión

La exploración del dataset Iris demuestra la importancia del análisis visual antes del modelado. Hemos confirmado que las dimensiones del pétalo son mucho más informativas que las del sépalo para distinguir especies. La fuerte correlación entre variables sugiere oportunidades para reducción de dimensionalidad.

**Próximos pasos:** Probar algoritmos de clasificación simples como K-Nearest Neighbors (KNN) o Árboles de Decisión utilizando solo las variables del pétalo. Investigar si la eliminación de variables correlacionadas afecta el rendimiento del modelo. Aplicar técnicas de clustering (K-Means) para ver si podemos recuperar los grupos de especies sin usar las etiquetas.
